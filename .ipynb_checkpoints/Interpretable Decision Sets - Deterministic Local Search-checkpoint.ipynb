{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# itemset (each rule predicate --> class label)\n",
    "class rule:\n",
    "    \n",
    "    def __init__(self,feature_list,value_list,class_label):\n",
    "        self.itemset = set()\n",
    "        self.class_label = None\n",
    "        self.add_item(feature_list,value_list)\n",
    "        self.set_class_label(class_label)\n",
    "    \n",
    "    def add_item(self,feature_list,value_list):\n",
    "        \n",
    "        if len(feature_list) != len(value_list):\n",
    "            print(\"Some error in inputting feature value pairs\")\n",
    "            return\n",
    "        for i in range(0,len(feature_list)):\n",
    "            self.itemset.add((feature_list[i],value_list[i]))\n",
    "    \n",
    "    def print_rule(self):\n",
    "        s = \"If \"\n",
    "        for item in self.itemset:\n",
    "            s += str(item[0]) + \" == \" +str(item[1]) + \" and \"\n",
    "        s = s[:-5]\n",
    "        s += \", then \"\n",
    "        s += str(self.class_label)\n",
    "        print(s)\n",
    "        \n",
    "    def all_predicates_same(self, r):\n",
    "        return self.itemset == r.itemset\n",
    "    \n",
    "    def class_label_same(self,r):\n",
    "        return self.class_label == r.class_label\n",
    "            \n",
    "    def set_class_label(self,label):\n",
    "        self.class_label = label\n",
    "        \n",
    "    def get_length(self):\n",
    "        return len(self.itemset)\n",
    "    \n",
    "    def get_cover(self, df):\n",
    "        dfnew = df.copy()\n",
    "        for pattern in self.itemset: \n",
    "            dfnew = dfnew[dfnew[pattern[0]] == pattern[1]]\n",
    "        return list(dfnew.index.values)\n",
    "\n",
    "    def get_correct_cover(self, df, Y):\n",
    "        indexes_points_covered = self.get_cover(df) # indices of all points satisfying the rule\n",
    "        Y_arr = pd.Series(Y)                    # make a series of all Y labels\n",
    "        labels_covered_points = list(Y_arr[indexes_points_covered])   # get a list only of Y labels of the points covered\n",
    "        correct_cover = []\n",
    "        for ind in range(0,len(labels_covered_points)):\n",
    "            if labels_covered_points[ind] == self.class_label:\n",
    "                correct_cover.append(indexes_points_covered[ind])\n",
    "        return correct_cover, indexes_points_covered\n",
    "    \n",
    "    def get_incorrect_cover(self, df, Y):\n",
    "        correct_cover, full_cover = self.get_correct_cover(df, Y)\n",
    "        return (sorted(list(set(full_cover) - set(correct_cover))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_apriori(df, support_thres):\n",
    "    # the idea is to basically make a list of strings out of df and run apriori api on it \n",
    "    # return the frequent itemsets\n",
    "    dataset = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        temp = []\n",
    "        for col_name in df.columns:\n",
    "            temp.append(col_name+\"=\"+str(df[col_name][i]))\n",
    "        dataset.append(temp)\n",
    "\n",
    "    results = list(apriori(dataset, min_support=support_thres))\n",
    "    \n",
    "    list_itemsets = []\n",
    "    for ele in results:\n",
    "        temp = []\n",
    "        for pred in ele.items:\n",
    "            temp.append(pred)\n",
    "        list_itemsets.append(temp)\n",
    "\n",
    "    return list_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createrules(freq_itemsets, labels_set):\n",
    "    # create a list of rule objects from frequent itemsets \n",
    "    list_of_rules = []\n",
    "    for one_itemset in freq_itemsets:\n",
    "        feature_list = []\n",
    "        value_list = []\n",
    "        for pattern in one_itemset:\n",
    "            fea_val = pattern.split(\"=\")\n",
    "            feature_list.append(fea_val[0])\n",
    "            value_list.append(fea_val[1])\n",
    "        for each_label in labels_set:\n",
    "            temp_rule = rule(feature_list,value_list,each_label)\n",
    "            list_of_rules.append(temp_rule)\n",
    "\n",
    "    return list_of_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_rule_length(list_rules):\n",
    "    len_arr = []\n",
    "    for r in list_rules:\n",
    "        len_arr.append(r.get_length())\n",
    "    return max(len_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlap(r1, r2, df):\n",
    "    return sorted(list(set(r1.get_cover(df)).intersection(set(r2.get_cover(df)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func_evaluation(soln_set, list_rules, df, Y, lambda_array):\n",
    "    # evaluate the objective function based on rules in solution set \n",
    "    # soln set is a set of indexes which when used to index elements in list_rules point to the exact rules in the solution set\n",
    "    # compute f1 through f7 and we assume there are 7 lambdas in lambda_array\n",
    "    f = [] #stores values of f1 through f7; \n",
    "    \n",
    "    # f0 term\n",
    "    f0 = len(list_rules) - len(soln_set) # |S| - size(R)\n",
    "    f.append(f0)\n",
    "    \n",
    "    # f1 term\n",
    "    Lmax = max_rule_length(list_rules)\n",
    "    sum_rule_length = 0.0\n",
    "    for rule_index in soln_set:\n",
    "        sum_rule_length += list_rules[rule_index].get_length()\n",
    "    \n",
    "    f1 = Lmax * len(list_rules) - sum_rule_length\n",
    "    f.append(f1)\n",
    "    \n",
    "    # f2 term - intraclass overlap\n",
    "    sum_overlap_intraclass = 0.0\n",
    "    for r1_index in soln_set:\n",
    "        for r2_index in soln_set:\n",
    "            if r1_index >= r2_index:\n",
    "                continue\n",
    "            if list_rules[r1_index].class_label == list_rules[r2_index].class_label:\n",
    "                sum_overlap_intraclass += len(overlap(list_rules[r1_index], list_rules[r2_index],df))\n",
    "    f2 = df.shape[0] * len(list_rules) * len(list_rules) - sum_overlap_intraclass\n",
    "    f.append(f2)\n",
    "    \n",
    "    # f3 term - interclass overlap\n",
    "    sum_overlap_interclass = 0.0\n",
    "    for r1_index in soln_set:\n",
    "        for r2_index in soln_set:\n",
    "            if r1_index >= r2_index:\n",
    "                continue\n",
    "            if list_rules[r1_index].class_label != list_rules[r2_index].class_label:\n",
    "                sum_overlap_interclass += len(overlap(list_rules[r1_index], list_rules[r2_index],df))\n",
    "    f3 = df.shape[0] * len(list_rules) * len(list_rules) - sum_overlap_interclass\n",
    "    f.append(f3)\n",
    "    \n",
    "    # f4 term - coverage of all classes\n",
    "    classes_covered = set() # set\n",
    "    for index in soln_set:\n",
    "        classes_covered.add(list_rules[index].class_label)\n",
    "    f4 = len(classes_covered)\n",
    "    f.append(f4)\n",
    "    \n",
    "    # f5 term - accuracy\n",
    "    sum_incorrect_cover = 0.0\n",
    "    for index in soln_set:\n",
    "        sum_incorrect_cover += len(list_rules[index].get_incorrect_cover(df,Y))\n",
    "    f5 = df.shape[0] * len(list_rules) - sum_incorrect_cover\n",
    "    f.append(f5)\n",
    "    \n",
    "    #f6 term - cover correctly with at least one rule\n",
    "    atleast_once_correctly_covered = set()\n",
    "    for index in soln_set:\n",
    "        correct_cover, full_cover = list_rules[index].get_correct_cover(df,Y)\n",
    "        atleast_once_correctly_covered = atleast_once_correctly_covered.union(set(correct_cover))\n",
    "    f6 = len(atleast_once_correctly_covered)\n",
    "    f.append(f6)\n",
    "    \n",
    "    obj_val = 0.0\n",
    "    for i in range(7):\n",
    "        obj_val += f[i] * lambda_array[i]\n",
    "    \n",
    "    #print(f)\n",
    "    return obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deterministic_local_search(list_rules, df, Y, lambda_array, epsilon):\n",
    "    # step by step implementation of deterministic local search algorithm in the \n",
    "    # FOCS paper: https://people.csail.mit.edu/mirrokni/focs07.pdf (page 4-5)\n",
    "    \n",
    "    #initialize soln_set\n",
    "    soln_set = set()\n",
    "    n = len(list_rules)\n",
    "    \n",
    "    # step 1: find out the element with maximum objective function value and initialize soln set with it\n",
    "    each_obj_val = []\n",
    "    for ind in range(len(list_rules)):\n",
    "        each_obj_val.append(func_evaluation(set([ind]), list_rules, df, Y, lambda_array))\n",
    "        \n",
    "    best_element = np.argmax(each_obj_val)\n",
    "    soln_set.add(best_element)\n",
    "    S_func_val = each_obj_val[best_element]\n",
    "    \n",
    "    restart_step2 = False\n",
    "    \n",
    "    # step 2: if there exists an element which is good, add it to soln set and repeat\n",
    "    while True:\n",
    "        \n",
    "        each_obj_val = []\n",
    "        \n",
    "        for ind in set(range(len(list_rules))) - soln_set:\n",
    "            func_val = func_evaluation(soln_set.union(set([ind])), list_rules, df, Y, lambda_array)\n",
    "            \n",
    "            if func_val > (1.0 + epsilon/(n*n)) * S_func_val:\n",
    "                soln_set.add(ind)\n",
    "                print(\"Adding rule \"+str(ind))\n",
    "                S_func_val = func_val\n",
    "                restart_step2 = True\n",
    "                break\n",
    "                \n",
    "        if restart_step2:\n",
    "            restart_step2 = False\n",
    "            continue\n",
    "            \n",
    "        for ind in soln_set:\n",
    "            func_val = func_evaluation(soln_set - set([ind]), list_rules, df, Y, lambda_array)\n",
    "            \n",
    "            if func_val > (1.0 + epsilon/(n*n)) * S_func_val:\n",
    "                soln_set.remove(ind)\n",
    "                print(\"Removing rule \"+str(ind))\n",
    "                S_func_val = func_val\n",
    "                restart_step2 = True\n",
    "                break\n",
    "        \n",
    "        if restart_step2:\n",
    "            restart_step2 = False\n",
    "            continue\n",
    "        \n",
    "        s1 = func_evaluation(soln_set, list_rules, df, Y, lambda_array)\n",
    "        s2 = func_evaluation(set(range(len(list_rules))) - soln_set, list_rules, df, Y, lambda_array)\n",
    "        \n",
    "        print(s1)\n",
    "        print(s2)\n",
    "        \n",
    "        if s1 >= s2:\n",
    "            return soln_set, s1\n",
    "        else: \n",
    "            return set(range(len(list_rules))) - soln_set, s2\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Died</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Died  Survived\n",
       "0     1         0\n",
       "1     1         0\n",
       "2     1         0\n",
       "3     1         0\n",
       "4     1         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic_train.tab',' ', header=None, names=['Passenger_Cat', 'Age_Cat', 'Gender'])\n",
    "df1 = pd.read_csv('titanic_train.Y', ' ', header=None, names=['Died', 'Survived'])\n",
    "Y = list(df1['Died'].values)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "If Age_Cat == adult, then 0\n",
      "If Age_Cat == adult, then 1\n",
      "If Gender == female, then 0\n",
      "If Gender == female, then 1\n",
      "If Gender == male, then 0\n",
      "If Gender == male, then 1\n",
      "If Passenger_Cat == 1st_class, then 0\n",
      "If Passenger_Cat == 1st_class, then 1\n",
      "If Passenger_Cat == 2nd_class, then 0\n",
      "If Passenger_Cat == 2nd_class, then 1\n",
      "If Passenger_Cat == 3rd_class, then 0\n",
      "If Passenger_Cat == 3rd_class, then 1\n",
      "If Passenger_Cat == crew, then 0\n",
      "If Passenger_Cat == crew, then 1\n",
      "If Gender == female and Age_Cat == adult, then 0\n",
      "If Gender == female and Age_Cat == adult, then 1\n",
      "If Gender == male and Age_Cat == adult, then 0\n",
      "If Gender == male and Age_Cat == adult, then 1\n",
      "If Passenger_Cat == 1st_class and Age_Cat == adult, then 0\n",
      "If Passenger_Cat == 1st_class and Age_Cat == adult, then 1\n",
      "If Passenger_Cat == 2nd_class and Age_Cat == adult, then 0\n",
      "If Passenger_Cat == 2nd_class and Age_Cat == adult, then 1\n",
      "If Passenger_Cat == 3rd_class and Age_Cat == adult, then 0\n",
      "If Passenger_Cat == 3rd_class and Age_Cat == adult, then 1\n",
      "If Passenger_Cat == crew and Age_Cat == adult, then 0\n",
      "If Passenger_Cat == crew and Age_Cat == adult, then 1\n",
      "If Passenger_Cat == 3rd_class and Gender == male, then 0\n",
      "If Passenger_Cat == 3rd_class and Gender == male, then 1\n",
      "If Gender == male and Passenger_Cat == crew, then 0\n",
      "If Gender == male and Passenger_Cat == crew, then 1\n",
      "If Passenger_Cat == 3rd_class and Gender == male and Age_Cat == adult, then 0\n",
      "If Passenger_Cat == 3rd_class and Gender == male and Age_Cat == adult, then 1\n",
      "If Gender == male and Passenger_Cat == crew and Age_Cat == adult, then 0\n",
      "If Gender == male and Passenger_Cat == crew and Age_Cat == adult, then 1\n",
      "Adding rule 2\n",
      "2066193.5\n",
      "2009047.5\n",
      "{2, 5}\n",
      "2066193.5\n"
     ]
    }
   ],
   "source": [
    "itemsets = run_apriori(df, 0.1)\n",
    "list_of_rules = createrules(itemsets, list(set(Y)))\n",
    "print(\"----------------------\")\n",
    "for r in list_of_rules:\n",
    "    r.print_rule()\n",
    "\n",
    "lambda_array = [0.5]*7     # use separate hyperparamter search routine\n",
    "epsilon = 0.05\n",
    "soln_set, obj_val = deterministic_local_search(list_of_rules, df, Y, lambda_array, epsilon)\n",
    "print(soln_set)\n",
    "print(obj_val)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
